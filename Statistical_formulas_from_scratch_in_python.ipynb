{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Statistical_formulas_from_scratch_in_python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWS9hBd2x5cVQ2hcdFT+dm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taaniya/Statistical_tests/blob/master/Statistical_formulas_from_scratch_in_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK5Qb08dmLL8"
      },
      "source": [
        "#### Pearson correlation\n",
        "\n",
        "* This correlation method is used to measure the strength of linear relationship between 2 variables\n",
        "\n",
        "* Assumes the 2 variables roughly come from normal distribution\n",
        "\n",
        "* +1 -> highly correlated \n",
        "* -1 -> negatively correlated \n",
        "* 0 -> no **linear correlation**, the variables may be non-linearly correlated though \n",
        "* The magnitude indicating the strength of relationship. If the variables are highly correlated (-1 / +1), we can use 1 variable to predict the other\n",
        "\n",
        "* The alternative hypothesis for the Pearson correlation test is the linear correlation between two variables X and Y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUnaimoZlWxb"
      },
      "source": [
        "#### Spearman correlation\n",
        "\n",
        "* Non-parametric test of statistical dependence for 2 variables.\n",
        "Non-parametric, since it doesn't assume any distribution for the 2 variables\n",
        "\n",
        "* This is useful in cases when the 2 variables donot come from normal distribution and is also robust to the effect of outliers.\n",
        "\n",
        "* Hypothesis for the Spearmanâ€™s correlation test states that the correlation between two variables X and Y corresponds to a monotonic function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXfwDKgrlJj3"
      },
      "source": [
        "def getPearsonCorrelation(df, feature1, feature2):\n",
        "    \"\"\"\n",
        "    eg. # getPearsonCorrelation(sample, 'votes', 'approx_cost(for two people)')\n",
        "    \"\"\"\n",
        "    mu1, mu2 = df[feature1].mean(),df[feature2].mean()\n",
        "    print(mu1, mu2)\n",
        "    std1, std2 = df[feature1].std(), df[feature2].std()\n",
        "    print(std1, std2)\n",
        "    cov = np.mean((df[feature1] - mu1) * (df[feature2] - mu2))\n",
        "    r = cov/(std1 * std2)\n",
        "    return r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x67O6kJzpxIl"
      },
      "source": [
        "### Coefficient of Variation\n",
        "\n",
        "This statistical measure of relative distribution of data points around the mean. More the value, higher is the dispersion.\n",
        "\n",
        "$ CV = \\frac{\\sigma}{\\mu} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF7Cn35Kp50l"
      },
      "source": [
        "def getCoefficientOfVariation(df, featureCol):\n",
        "    \"\"\"\n",
        "    Returns Coefficient of Variance (CV) for featureCol\n",
        "    CV = std / mu\n",
        "\n",
        "    eg. getCoefficientOfVariation(zomato_df, 'votes')\n",
        "    \"\"\"\n",
        "    cv = df[featureCol].std() / df[featureCol].mean()\n",
        "    return cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjIJ_7mmp1Dl"
      },
      "source": [
        "### Kurtosis\n",
        "\n",
        "Kurtosis is the 4th central moment of a dataset divided by square of variance , for measuring heaviness of tails of distribution compared to a normal distribution of same variance.\n",
        "\n",
        "heavy tails -> high kurtosis (called Leptokurtic). eg. student-t distribution with kurtosis = $ \\infty$ at df <= 4\n",
        "light tails -> low kurtosis (called platykurtic)  eg. uniform distribution with kurtosis = \n",
        "\n",
        "The above measure of kurtosis if Fisher's kurtosis which is excess kurtosis\n",
        "\n",
        "excess kurtosis = kurtosis - 3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivYZ4nNWpvyE"
      },
      "source": [
        "def computeKurtosis(df, featureCol):\n",
        "    \"\"\"\n",
        "    Returns Fisher's Kurtosis for featureCol by substracting 3 from k.\n",
        "    eg. computeKurtosis(zomato_df, 'votes')\n",
        "    \"\"\"\n",
        "    mu = df[featureCol].mean()\n",
        "    var = df[featureCol].var()\n",
        "    centralized_mean = np.mean(np.power(df[featureCol].values - mu, 4))\n",
        "    k = centralized_mean / np.square(var)\n",
        "    k = k - 3                                        # Fisher's definition\n",
        "    return k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRNe-kIBncbF"
      },
      "source": [
        "#### References\n",
        "\n",
        "* [Probability and Statistics for Programmers - PDF](http://greenteapress.com/thinkstats/thinkstats.pdf)\n",
        "\n",
        "* https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0697-7"
      ]
    }
  ]
}